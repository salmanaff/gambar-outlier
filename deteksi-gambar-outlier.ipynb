{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "CJod-uiV8z4l",
        "aRNWwivi83Px",
        "cRu0p55B_p2t",
        "hSXHoF-0AX0h",
        "U_ejLx0S_ryt",
        "M-LTx2T7_tyK",
        "5hSqf7CMsDS8",
        "cjUzjD87zK-0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/salmanaff/gambar-outlier/blob/main/deteksi-gambar-outlier.ipynb)\n",
        "\n",
        "# Codes"
      ],
      "metadata": {
        "id": "CJod-uiV8z4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General"
      ],
      "metadata": {
        "id": "aRNWwivi83Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q glasbey\n",
        "import glasbey\n",
        "\n",
        "import re\n",
        "import os\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "from IPython.display import display, clear_output\n",
        "from traitlets import traitlets\n",
        "\n",
        "class LoadedButton(widgets.Button):\n",
        "    \"\"\"A button that can holds a value as a attribute.\"\"\"\n",
        "    def __init__(self, value=None, *args, **kwargs):\n",
        "        super(LoadedButton, self).__init__(*args, **kwargs)\n",
        "        # Create the value attribute.\n",
        "        self.add_traits(value=traitlets.Any(value))\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as t\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "model_dir = 'models'\n",
        "data_dir = 'dataset'\n",
        "try:\n",
        "  import google.colab\n",
        "  os.mkdir(model_dir)\n",
        "  os.mkdir(data_dir)\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "device = get_default_device()"
      ],
      "metadata": {
        "id": "dXR4wbSl_wNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "cRu0p55B_p2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "6kkX6j5c_v7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "hSXHoF-0AX0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_models():\n",
        "    classification_models_name = []\n",
        "    for name in dir(models):\n",
        "        if name.islower() and (name.startswith('resnet')\n",
        "                              #  name.startswith('densenet') or\n",
        "                              #  name.startswith('inception') or\n",
        "                              #  name.startswith('mobilenet') or\n",
        "                              #  name.startswith('googlenet') or\n",
        "                              #  name.startswith('vgg')\n",
        "                              ):\n",
        "            classification_models_name.append(name)\n",
        "    return classification_models_name\n",
        "model_list = gen_models()\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        \"calculate loss for a batch of training data\"\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    def validation_step(self, batch):\n",
        "        \"calculate loss & accuracy for a batch of validation data\"\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "\n",
        "class base_net(ImageClassificationBase):\n",
        "    def __init__(self, model, num_classes):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = model\n",
        "        # Replace last layer\n",
        "        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "LJ0TKxSWAfTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "U_ejLx0S_ryt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim_list = {\n",
        "    'SGD': optim.SGD,\n",
        "    'RMSprop': optim.RMSprop,\n",
        "    'Adagrad': optim.Adagrad,\n",
        "    'Adam': optim.Adam,\n",
        "    'AdamW': optim.AdamW,\n",
        "}\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_model_weights = None\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss:\n",
        "            if self.verbose:\n",
        "                print(f'Validation loss improved by: {self.best_loss-val_loss:.4f}')\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            if self.restore_best_weights:\n",
        "                self.best_model_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'Validation loss did not improve: {val_loss:.4f}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.restore_best_weights and self.best_model_weights is not None:\n",
        "                    model.load_state_dict(self.best_model_weights)\n",
        "                    if self.verbose:\n",
        "                        print(\"Restored best model weights.\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_fe(epochs, lr, model, train_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        train_loss = torch.stack(train_losses).mean().item()\n",
        "        print(f\"Epoch [{epoch}], train loss: {train_loss}\")\n",
        "        history.append(train_loss)\n",
        "        early_stopping(train_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "    return history\n",
        "\n",
        "def train(b):\n",
        "  DATA_TRANSFORM = t.Compose([t.Resize(image_dim.value),\n",
        "                                t.ToTensor()])\n",
        "  DATA_DS = ImageFolder(folder_path.value, DATA_TRANSFORM)\n",
        "  TRAIN_DL = DataLoader(DATA_DS,\n",
        "                        batch_size.value,\n",
        "                        shuffle=True,\n",
        "                        num_workers=num_workers.value)\n",
        "  TRAIN_DL = DeviceDataLoader(TRAIN_DL, device)\n",
        "  trained = base_net(models.get_model(model_dd.value), len(DATA_DS.classes))\n",
        "  trained = to_device(trained, device)\n",
        "\n",
        "  history = []\n",
        "  with output3:\n",
        "    clear_output(wait=True)\n",
        "    history += fit_fe(epoch.value,\n",
        "                      lr.value,\n",
        "                      trained,\n",
        "                      TRAIN_DL,\n",
        "                      optim_list[optimizer.value])\n",
        "  b.value = {\n",
        "      'data': DATA_DS,\n",
        "      'history': history,\n",
        "      'model': trained\n",
        "  }"
      ],
      "metadata": {
        "id": "LewaZVW__wsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UMAP"
      ],
      "metadata": {
        "id": "M-LTx2T7_tyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import base64\n",
        "import umap\n",
        "\n",
        "from bokeh.io import show, output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
        "from bokeh.palettes import Spectral10\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "def get_embedding(model, dl, device):\n",
        "    \"\"\"extract feature embeddings from image\"\"\"\n",
        "\n",
        "    # Remove classification layer\n",
        "    model_fe = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "    to_device(model_fe, device)\n",
        "\n",
        "    embeds = []\n",
        "    classes = []\n",
        "    # Iterate through batches\n",
        "    progress_bar = tqdm(total=len(dl))\n",
        "    with torch.no_grad():\n",
        "       for batch in dl:\n",
        "           images, labels = batch\n",
        "           outputs = model_fe(images)\n",
        "           classes.append(labels)\n",
        "           embeds.append(outputs)\n",
        "           progress_bar.update(1)\n",
        "    progress_bar.close()\n",
        "\n",
        "    embed = [embed.squeeze(dim=2).squeeze(dim=2).cpu() for embed in embeds]\n",
        "    embed = torch.cat(embed, dim=0).tolist()\n",
        "    classes = torch.cat(classes, dim=0).tolist()\n",
        "    return embed, classes\n",
        "\n",
        "def embeddable_image(data):\n",
        "  img = Image.open(data[0])\n",
        "  img.thumbnail((64, 64), Image.Resampling.BICUBIC)\n",
        "  buffer = BytesIO()\n",
        "  img.save(buffer, format='png')\n",
        "  for_encoding = buffer.getvalue()\n",
        "  return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()\n",
        "\n",
        "def create_df(b):\n",
        "  DATA_DS = train_btn.value['data']\n",
        "  TEST_DL = DataLoader(DATA_DS, batch_size.value, shuffle=False, num_workers=num_workers.value)\n",
        "  TEST_DL = DeviceDataLoader(TEST_DL, device)\n",
        "\n",
        "  model = train_btn.value['model']\n",
        "  model.eval()\n",
        "\n",
        "  with output4:\n",
        "    print(\"Getting image embedding:\")\n",
        "    embed, y = get_embedding(model.network, TEST_DL, device)\n",
        "\n",
        "    print(\"\\nCreating UMAP embedding:\")\n",
        "    reducer = umap.UMAP(verbose=True)\n",
        "    reducer.fit(embed)\n",
        "    embedding = reducer.transform(embed)\n",
        "    clear_output(wait=True)\n",
        "\n",
        "  images_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
        "  images_df['label'] = [DATA_DS.classes[x] for x in DATA_DS.targets]\n",
        "  images_df['name'] = [path.split(\"/\")[-1].split('.')[0] for path, _ in DATA_DS.imgs]\n",
        "  images_df['image'] = list(map(embeddable_image, DATA_DS.imgs))\n",
        "\n",
        "  cmap = glasbey.create_palette(palette_size=len(DATA_DS.classes))\n",
        "  images_df['color'] = [cmap[x] for x in DATA_DS.targets]\n",
        "  b.value = images_df\n",
        "  iqr_dd.options = DATA_DS.classes\n",
        "  iqr_dd.value = DATA_DS.classes[0]\n",
        "\n",
        "def plot_umap(b):\n",
        "  df = embed_btn.value\n",
        "  color_mapping = CategoricalColorMapper(\n",
        "      factors=df.label.unique(),\n",
        "      palette=df.color.unique()\n",
        "  )\n",
        "  p = figure(\n",
        "      width=800,\n",
        "      height=600,\n",
        "      title=\"UMAP Scatter Plot\",\n",
        "      toolbar_location=\"above\",\n",
        "      x_axis_label = 'FEATURE 1',\n",
        "      y_axis_label = 'FEATURE 2',\n",
        "      tools=('box_zoom, pan, wheel_zoom, reset, save')\n",
        "  )\n",
        "  p.add_tools(HoverTool(tooltips=\"\"\"\n",
        "  <div>\n",
        "      <div >\n",
        "          <img src='@image' style='display: block; margin: 3px auto 0px'/>\n",
        "      </div>\n",
        "      <div style='text-align: center; margin-bottom: 2px'>\n",
        "          <span style='font-size: 14px'>@name</span>\n",
        "      </div>\n",
        "  </div>\n",
        "  \"\"\"))\n",
        "\n",
        "  for labs in df.label.unique():\n",
        "      new_df = df[df.label==labs]\n",
        "      datasource = ColumnDataSource(new_df)\n",
        "      p.scatter('x', 'y',\n",
        "                source=datasource,\n",
        "                legend_label=labs,\n",
        "                color=dict(field='label', transform=color_mapping),\n",
        "                line_alpha=0,\n",
        "                fill_alpha=0.5,\n",
        "                size=10)\n",
        "  p.legend.title = \"Classess\"\n",
        "  p.legend.location = \"top_right\"\n",
        "  p.legend.click_policy=\"hide\"\n",
        "\n",
        "  show(p)"
      ],
      "metadata": {
        "id": "Ur7d_6lgBBcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IQR"
      ],
      "metadata": {
        "id": "5hSqf7CMsDS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_iqr(df, label, color):\n",
        "  fig, axs=plt.subplots(2,2,figsize=(8,6), gridspec_kw={'hspace': .01,\n",
        "                                                        'wspace': .01,\n",
        "                                                        'width_ratios': [5, 1],\n",
        "                                                        'height_ratios': [1, 5]})\n",
        "  axs[0,0].axis(\"off\")\n",
        "  axs[0,1].axis(\"off\")\n",
        "  axs[1,1].axis(\"off\")\n",
        "\n",
        "  sns.boxplot(data=df, x='x', y='label', ax=axs[0,0], orient='h', legend=False, color=color)\n",
        "  sns.boxplot(data=df, y='y', x='label', ax=axs[1,1], orient='v', legend=False, color=color)\n",
        "  sns.scatterplot(data=df, x=\"x\", y=\"y\", ax=axs[1,0], color=color)\n",
        "\n",
        "  fig.suptitle(f\"Scatter and Box Plot for {label}\")\n",
        "  axs[1,0].set_xlabel(\"Feature 1\")\n",
        "  axs[1,0].set_ylabel(\"Feature 2\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "GS07v6dSsCnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_plot(total, Cols=5):\n",
        "    '''get column and row length to fit all'''\n",
        "    Rows = total // Cols\n",
        "    if total % Cols != 0:\n",
        "        Rows += 1\n",
        "    return Rows, Cols\n",
        "\n",
        "def decode_image(img):\n",
        "  img = base64.b64decode(img)\n",
        "  img = BytesIO(img)\n",
        "  img = Image.open(img)\n",
        "  return img\n",
        "\n",
        "def plot_images(outlier, name, n):\n",
        "  max=10\n",
        "  scale=1\n",
        "\n",
        "  if n==1:\n",
        "    fig, axes = plt.subplots(1, n, figsize=(n*scale,1*scale+.5))\n",
        "    img = decode_image(outlier['image'][0].split(',')[-1])\n",
        "    axes.imshow(img)\n",
        "    axes.set_xlabel(outlier['name'][0])\n",
        "    plt.setp(axes, xticks=[], yticks=[])\n",
        "    plt.suptitle(f\"{name} outlier\")\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "  if n<max:\n",
        "    fig, axes = plt.subplots(1, n, figsize=(n*scale,1*scale+.5))\n",
        "  else:\n",
        "    col, row = dynamic_plot(n, max)\n",
        "    fig, axes = plt.subplots(col, row, figsize=(row*scale,col*scale))\n",
        "\n",
        "  plt.setp(axes, xticks=[], yticks=[])\n",
        "  for i, ax in enumerate(axes.flatten()):\n",
        "    if i>=n:\n",
        "      ax.axis(\"off\")\n",
        "    else:\n",
        "      img = decode_image(outlier['image'][i].split(',')[-1])\n",
        "      ax.set_xlabel(outlier['name'][i])\n",
        "      ax.imshow(img)\n",
        "  plt.suptitle(f\"{name} outlier\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "19K292GEsI1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  df = embed_btn.value\n",
        "  df = df[df.label==x.new].reset_index()\n",
        "  embed = df[['x', 'y']]\n",
        "\n",
        "  Q1, Q3 = np.percentile(embed, [25, 75], axis=0)\n",
        "  IQR = Q3-Q1\n",
        "  LB = Q1-1.5*IQR\n",
        "  UB = Q3+1.5*IQR\n",
        "  outlier = np.unique(np.where((embed<=LB) | (embed>=UB))[0])\n",
        "  n = len(outlier)\n",
        "  outlier = df.iloc[outlier].reset_index()\n",
        "\n",
        "  with output6:\n",
        "    embed = df[['x', 'y']]\n",
        "    plot_iqr(df, x.new, df['color'][0])\n",
        "    clear_output(wait=True)\n",
        "\n",
        "  with output7:\n",
        "    if n==0:\n",
        "      print(\"No outlier found!\")\n",
        "    else:\n",
        "      plot_images(outlier, x.new, n)\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "id": "Rvy5ai6-sLF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI bits"
      ],
      "metadata": {
        "id": "cjUzjD87zK-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = widgets.Text(placeholder='https://example.com/dataset.zip')\n",
        "dl_btn = LoadedButton(description=\"Download\", value=[])\n",
        "\n",
        "def downloader(b):\n",
        "  file = re.split('/', link.value)[-1]\n",
        "  with output1:\n",
        "    if file not in os.listdir():\n",
        "      !wget {link.value}\n",
        "      clear_output(wait=False)\n",
        "      print(f\"Downloaded {file} from {link.value}\")\n",
        "      !unzip -qq -o {file} -d \"/content/dataset\"\n",
        "      print(f\"Unzipped {file} to '/content/dataset'\")\n",
        "      folder_path.options = [f\"{data_dir}/{f}\" for f in os.listdir(data_dir)]\n",
        "      folder_path.value = f\"{data_dir}/{os.listdir(data_dir)[0]}\"\n",
        "    else:\n",
        "      print(\"file already uploaded\")\n",
        "\n",
        "dl_btn.on_click(downloader)\n",
        "\n",
        "title1 = widgets.HTML(value=\"<h1>Download dataset</h1>\")\n",
        "ui1 = widgets.HBox([link, dl_btn])"
      ],
      "metadata": {
        "id": "BbOr6rWizMte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [f\"{data_dir}/{f}\" for f in os.listdir(data_dir)]\n",
        "folder_path = widgets.Dropdown(description='Image folder:', options=dataset)\n",
        "image_dim = widgets.IntText(value=224, description='Image dim:')\n",
        "batch_size = widgets.IntText(value=32, description='Batch size:')\n",
        "num_workers = widgets.IntText(value=2, description='Num worker:')\n",
        "\n",
        "title2 = widgets.HTML(value=\"<h1>Dataset options</h1>\")\n",
        "ui2 = widgets.VBox([title2, folder_path, image_dim, batch_size, num_workers])"
      ],
      "metadata": {
        "id": "swN_xpUezOtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dd = widgets.Dropdown(options=model_list,\n",
        "                            value='resnet18',\n",
        "                            description='Model:')\n",
        "epoch = widgets.IntText(value=2, description='Epoch:')\n",
        "lr = widgets.FloatText(value=0.00001, description='Learn Rate:')\n",
        "optimizer = widgets.Dropdown(options=list(optim_list.keys()),\n",
        "                             value='Adam',\n",
        "                             description='Optimizer:',)\n",
        "\n",
        "train_btn = LoadedButton(description=\"Train\")\n",
        "train_btn.on_click(train)\n",
        "\n",
        "title3 = widgets.HTML(value=\"<h1>Training options</h1>\")\n",
        "ui3 = widgets.VBox([title3, model_dd, epoch, lr, optimizer, train_btn])\n",
        "output3 = widgets.Output()"
      ],
      "metadata": {
        "id": "F-vQHh84zQSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Interface"
      ],
      "metadata": {
        "id": "HSgWEw4I9Aw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "output1 = widgets.Output()\n",
        "display(title1, ui1, output1)\n",
        "ui23 = widgets.VBox([ui2, ui3])\n",
        "display(ui23)"
      ],
      "metadata": {
        "id": "x8sUiy9rK1_z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "output3 = widgets.Output()\n",
        "widgets.Accordion([output3])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "p0agrcRy2Gf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "embed_btn = LoadedButton(description=\"Get embed\")\n",
        "embed_btn.on_click(create_df)\n",
        "\n",
        "title4 = widgets.HTML(value=\"<h1>Outlier Detection</h1>\")\n",
        "output4 = widgets.Output()\n",
        "display(title4, embed_btn, output4)"
      ],
      "metadata": {
        "id": "BkDXh53ETZT4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "umap_btn = LoadedButton(description=\"Plot UMAP\")\n",
        "umap_btn.on_click(plot_umap)\n",
        "\n",
        "display(umap_btn)"
      ],
      "metadata": {
        "id": "mwUeBw00VqS0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "iqr_dd = widgets.Dropdown(options=[])\n",
        "iqr_dd.observe(f, names='value')\n",
        "\n",
        "output6 = widgets.Output()\n",
        "display(iqr_dd, output6)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SqRuTgr6dV5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "output7 = widgets.Output()\n",
        "display(output7)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6MU7Q1Q77yG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}